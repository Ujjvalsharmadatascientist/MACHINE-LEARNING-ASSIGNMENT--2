{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d3ceed3-d7ab-497b-abaf-3078d2c79915",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "ANS=1 Min-Max scaling, also known as normalization, is a data preprocessing technique that rescales numerical features to a specific range, typically between 0 and 1. It's commonly used before fitting machine learning models. \n",
    "\n",
    "It calculates the minimum and maximum values of the data.\n",
    "It scales each feature individually so that it falls within the specified range\n",
    "\n",
    "Simplicity: It's implemented in common machine learning libraries like scikit-learn.\n",
    "Relationship preservation: It maintains the order of the data points.\n",
    "Compatibility: It works well with distance-based algorithms\n",
    "\n",
    "If a feature's minimum value is 10 and its maximum value is 20, then a value of 15 after Min-Max scaling would be 0.5. This is because (15 - 10) / (20 - 10) = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "040bf13d-5eef-427e-8482-8d6d3f5bd3ce",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "ANS=Unit vector scaling\n",
    "This normally requires dividing each component by the Euclidean length of the vector. In certain applications, it can be practical to use the L1 norm of the feature vector. Like min-max scaling, the unit vector technique will produce values that range between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c64108fd-bf84-4bba-a7ab-32b75dd387b5",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "ANS=Principal Component Analysis (PCA) is a powerful technique used in data analysis, particularly for reducing the dimensionality of datasets while preserving crucial information. It does this by transforming the original variables into a set of new, uncorrelated variables called principal components"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ac51f1d-6ed2-47de-850b-ac07c2e4d78c",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75a29489-25ea-4912-97b8-b4bd10a7cf00",
   "metadata": {},
   "source": [
    " ANS= In Machine learning,there are independent variables or features on which our final output classification is done.When the no of these features increases it is difficult to visualize the data and work with it.\n",
    "\n",
    "For example ,taking the example MNIST database,which is a large database of handwritten digits that is commonly used for training various image processing systems. Each image in the dataset is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.Now our objective is, for a given image determine what digit it is?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
